{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "68206085",
   "metadata": {},
   "source": [
    "<h1>How Models Work</h1>\n",
    "\n",
    "Machine learning models are used to make predictions on previously unseen data (stock prices, housing prices, etc.).\n",
    "\n",
    "In Python we can create a variety of models (Decision Tree, Random Forest, etc.) using the scikit-learn module.\n",
    "\n",
    "After we create a model, we should fit/train the model, so it can capture and learn patterns from the training data.\n",
    "\n",
    "Once model training is complete, we can use it to make predictions on the target variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11d5fef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# modules\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.impute import SimpleImputer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "469a8403",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful Funcitons & Tools\n",
    "\n",
    "# pd.DataFrame.head()\n",
    "# pd.DataFrame.describe()\n",
    "# pd.DataFrame.columns\n",
    "\n",
    "\n",
    "# Creating a new DataFrame containing only feature columns\n",
    "# features = ['col1', 'col3', 'col5', 'col7']\n",
    "# X = dataset[features]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c196bbf7",
   "metadata": {},
   "source": [
    "<h2>Intro to Machine Learning At a Glance</h2>\n",
    "\n",
    "1. Read the training dataset into pandas DataFrame.\n",
    "2. Select target and features (X, y).\n",
    "3. Split the dataset into train and validation sets (X_train, X_val, y_train, y_val).\n",
    "4. Handle missing data (drop column, imputate both X_train and X_valid).\n",
    "5. Define, fit, predict, and evaluate models (we can use Mean Absolute Value to evaluate; we want lowest MAE). Choose the best model (create a function for this part).\n",
    "7. Re-fit the best model using the entire training dataset (X & y, instead of just X_train & y_train).\n",
    "8. Use the newly fitted model to predict the target with the test data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55c07cb7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "419067f3",
   "metadata": {},
   "source": [
    "- fitting == training\n",
    "- evaluate == score\n",
    "- \"in-sample\" scores are a bad indication of model accuracy (we want to evaluate on previously unseen data to obtain accurate model accruacy). therefore, we must split the dataset into training vs. validation set.\n",
    "- Underfitting vs. Overfitting; underfitting refers to failure to capture relevant patterns, leading to less accurate predictions. overfitting refers to capturing spurious patterns that won't recur in the future, leading to less accruate predictions.\n",
    "- just like decision tree, we can adjust the parameters of a random forest model, but they generally work reasonably well even without this tuning"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
